{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "import gensim\n",
    "import re\n",
    "import datetime\n",
    "import collections\n",
    "import random\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Dataset/cleaned_data.csv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FM20160429032ACC9MUHD</td>\n",
       "      <td>acea essere pronto giocare partita banda ultra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FM20160501023ACLAzwID</td>\n",
       "      <td>unico certezza momento essere prossimo tappa s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FM20160503035ACaNSzJD</td>\n",
       "      <td>potere aspettare mese luglio formalizzazione p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FM20160503035ACDx00JD</td>\n",
       "      <td>fondo chiuso aiutare piccolo medio impresa ita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FM20160428033ACi2kvGD</td>\n",
       "      <td>volto provocazione sortire effetto sperare ext...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0                                               body\n",
       "0  FM20160429032ACC9MUHD  acea essere pronto giocare partita banda ultra...\n",
       "1  FM20160501023ACLAzwID  unico certezza momento essere prossimo tappa s...\n",
       "2  FM20160503035ACaNSzJD  potere aspettare mese luglio formalizzazione p...\n",
       "3  FM20160503035ACDx00JD  fondo chiuso aiutare piccolo medio impresa ita...\n",
       "4  FM20160428033ACi2kvGD  volto provocazione sortire effetto sperare ext..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9283, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tagDocuments(text):\n",
    "    for i, line in enumerate(text):\n",
    "        if(i%1000 == 0):\n",
    "            print(\"> Iteration: \" + str(i))\n",
    "        yield gensim.models.doc2vec.TaggedDocument(\n",
    "            [w for w in \n",
    "             gensim.utils.simple_preprocess(line)], [i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract train data from dataframe into list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> START 2017-05-22 21:45:05.700830\n",
      "> Iteration: 0\n",
      "> Iteration: 1000\n",
      "> Iteration: 2000\n",
      "> Iteration: 3000\n",
      "> Iteration: 4000\n",
      "> Iteration: 5000\n",
      "> Iteration: 6000\n",
      "> Iteration: 7000\n",
      "> Iteration: 8000\n",
      "> Iteration: 9000\n",
      "> END 2017-05-22 21:45:07.769022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9283"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"> START %s\" % datetime.datetime.now())\n",
    "train_corpus = list(tagDocuments(train['body'].tolist()))\n",
    "print(\"> END %s\" % str(datetime.datetime.now()))\n",
    "\n",
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window = 20\n",
    "size = 20\n",
    "dm_concat = 1\n",
    "alpha = 0.02\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=size, min_count=10, \n",
    "                                      dm_concat= dm_concat, \n",
    "                                      window=window, alpha = alpha,iter=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 21:45:17,769 : INFO : collecting all words and their counts\n",
      "2017-05-22 21:45:17,773 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2017-05-22 21:45:18,109 : INFO : collected 28585 word types and 9283 unique tags from a corpus of 9283 examples and 1175199 words\n",
      "2017-05-22 21:45:18,110 : INFO : Loading a fresh vocabulary\n",
      "2017-05-22 21:45:18,142 : INFO : min_count=10 retains 7397 unique words (25% of original 28585, drops 21188)\n",
      "2017-05-22 21:45:18,144 : INFO : min_count=10 leaves 1123040 word corpus (95% of original 1175199, drops 52159)\n",
      "2017-05-22 21:45:18,168 : INFO : deleting the raw counts dictionary of 28585 items\n",
      "2017-05-22 21:45:18,171 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2017-05-22 21:45:18,172 : INFO : downsampling leaves estimated 1036816 word corpus (92.3% of prior 1123040)\n",
      "2017-05-22 21:45:18,173 : INFO : estimated required memory for 7397 words and 20 dimensions: 29295060 bytes\n",
      "2017-05-22 21:45:18,201 : INFO : using concatenative 820-dimensional layer1\n",
      "2017-05-22 21:45:18,202 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"doc2vec_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 21:45:24,639 : INFO : loading Doc2Vec object from doc2vec_model\n",
      "2017-05-22 21:45:24,893 : INFO : loading wv recursively from doc2vec_model.wv.* with mmap=None\n",
      "2017-05-22 21:45:24,893 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-05-22 21:45:24,894 : INFO : loading docvecs recursively from doc2vec_model.docvecs.* with mmap=None\n",
      "2017-05-22 21:45:24,895 : INFO : setting ignored attribute cum_table to None\n",
      "2017-05-22 21:45:24,897 : INFO : loaded doc2vec_model\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(str(os.getcwd()) + '/' + model_name):\n",
    "    %time model.train(train_corpus)\n",
    "    model.save(model_name)\n",
    "else:\n",
    "    model = gensim.models.doc2vec.Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-22 19:35:57,959 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    }
   ],
   "source": [
    "ranks = [] #per ogni documento l'indice che indica a che livello si trova nella lista dei simili a se stesso)\n",
    "\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model (raw):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(listOfRanks):\n",
    "    correct = 0\n",
    "    for e in listOfRanks:\n",
    "        if(e >= 0 | e <= 2):\n",
    "        #if( e == 0):\n",
    "            correct = correct + 1\n",
    "    return correct/len(listOfRanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598190240224066"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17726685, -0.00284267, -0.04112091, -0.18763816,  0.26730201,\n",
       "       -0.01805161, -0.15042204,  0.0606822 ,  0.00520629, -0.30798909,\n",
       "        0.26504353,  0.0281793 , -0.09364226, -0.02050012, -0.15537296,\n",
       "        0.01127828, -0.08701586,  0.06999869, -0.22491051, -0.13964911], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['oggi', 'voglio', 'comprare', 'una', 'azione', 'di', 'mediaset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9215"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab['gruppo'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (9282): «toscano aeroporto apprendere indiscrezione stampa commissione valutazione impatto ambientale ministero ambiente avere esprimere parere favorevole masterplan aeroporto amerigo vespucci firenze prevedere altro cosa realizzazione cosiddetto pista parallelo nuovo terminal aeroportuale quotare mercato telematico azionario organizzare gestire borsa italiano riservare qualsiasi commento merito fino pubblicazione parere relativo documentazione parte ministero riferire nota»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/c,d20,n5,w20,mc10,s0.001,t3):\n",
      "\n",
      "MOST (9282, 0.8520050048828125): «toscano aeroporto apprendere indiscrezione stampa commissione valutazione impatto ambientale ministero ambiente avere esprimere parere favorevole masterplan aeroporto amerigo vespucci firenze prevedere altro cosa realizzazione cosiddetto pista parallelo nuovo terminal aeroportuale quotare mercato telematico azionario organizzare gestire borsa italiano riservare qualsiasi commento merito fino pubblicazione parere relativo documentazione parte ministero riferire nota»\n",
      "\n",
      "MEDIAN (2934, 0.0059842318296432495): «olimpiade favorevole contrario candidatura roma olimpiade essere assolutamente favorevole candidatura olimpico anzi pensare grande prossimo anno valere pena investire ottico cambiamento localizzazione villaggio sperare essere problema concreto affrontare olimpiade essere_stare assegnare assegnare roma tema dossier approvare parte cono partire dire quadro essere_fare seguente innanzitutto cio considerare positivamente villaggio essere vicino impianto poi realizzazione flaminia salariare chiara mondo ambientalista pensare decisione prendere»\n",
      "\n",
      "LEAST (7028, -0.7801721692085266): «accordo tower kidstv mondo tv annunciare avere sottoscrivere tower kidstv gmbh produzione programma bambino sede vienna principale settore paese germanofoni contratto licenza attraverso mondo tv distributore due stagione serie successo abc beare europa est medio oriente asia africo contratto riferire nota durare mese diritto sublicenza diritto sfruttamento audiovisivo due stagione suddetto serie includere diritto trasmissione televisivo ogni piattaforma mezzo diffusione diritto video on demand»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (7542): «nuovo ingresso prelios agency trattare antonio chiatellino nominare head of capital leasing chiatellino avere recentemente lavorare banca esperia interno prelios agency ulteriormente team dedicare offerta servizio advisory brokerage investitore pubblico privato fondo immobiliare operatore istituzionale»\n",
      "\n",
      "Similar Document (2220, 0.7440720796585083): «milanoil consiglio amministrazione idea capital funds sgr avere deliberare terzo closing fondo idea taste of italy primo fondo privato equity italiano specializzare settore agroalimentare ammontare complessivo pari milione euro board avere deliberare inizio attività investimento fondo idea ccr corporate credit recovery particolare essere_stare esaminare esaminare investimento quattro società già presente portafoglio comparto credito fondo spiegare nota conferma strategia originariamente delineare prevedere rilancio sviluppo azienda fare parte comparto infine assemblea socio idea capital funds sgr avere aumentare numero consigliere consiglio amministrazione nominare nuovo consigliere indipendente persona piero gallo gallo avere recentemente concludere mandato direttore generale expo milano dopo essere_stare molto anno partner italian office bainandco idea capital funds sgr fondare dicembre dea capital società gruppo de agostini attivo alternativo asset management società conta miliardo massa gestire investire fondo fondo globale fondo diretto investire prevalentemente azienda italiano»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "\n",
    "doc_id = random.randint(0, len(train_corpus))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
